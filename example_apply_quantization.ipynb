{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install auto-gptq torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select model.\n",
    "MODEL_ID = \"meta-llama/Meta-Llama-3-8B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select dataset for calibration.\n",
    "# Choosing something that is as close as possible to your target use case is best.\n",
    "# Here, we selected a generic chat dataset.\n",
    "DATASET_ID = \"HuggingFaceH4/ultrachat_200k\"\n",
    "\n",
    "# Best practice is to use 4096, but 2048 can be good enough.\n",
    "MAX_SEQ_LEN = 4096\n",
    "\n",
    "# 512 samples is usually good enough, moving to 1024 can help sometimes.\n",
    "NUM_SAMPLES = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rshaw/.pyenv/versions/3.10.14/envs/auto-gptq/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Map: 100%|██████████| 512/512 [00:00<00:00, 4411.97 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Pre-process your dataset.\n",
    "# Its a good idea to use the chat template.\n",
    "def preprocess(example):\n",
    "    return {\"text\": tokenizer.apply_chat_template(\n",
    "        example[\"messages\"], tokenize=False,\n",
    "    )}\n",
    "\n",
    "dataset = load_dataset(DATASET_ID, split=\"train_sft\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "ds = dataset.shuffle().select(range(NUM_SAMPLES))\n",
    "ds = ds.map(preprocess)\n",
    "\n",
    "# BE CAREFUL WITH THE TOKENIZER\n",
    "#   apply_chat_template already adds the bos_token\n",
    "#   so we set add_special_token to false\n",
    "examples = [\n",
    "    tokenizer(\n",
    "        example[\"text\"],\n",
    "        padding=False, max_length=MAX_SEQ_LEN, truncation=True, add_special_tokens=False\n",
    "    ) for example in ds\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Explain how a company's ability to effectively develop products directly impacts its long-term growth and profitability, addressing key factors such as market research, innovation, risk management, and customer needs. Provide examples of successful product development strategies and how they have contributed to the growth of specific companies. Additionally, discuss the potential consequences of poor product development and how it can hinder a company's ability to achieve sustainable growth.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Product development is one of the primary drivers of long-term growth and profitability for a company. It involves identifying customer needs, conducting market research, and creating innovative solutions that meet those needs. The ability of a company to effectively develop products can impact its growth and profitability by influencing key factors such as market research, innovation, risk management, and customer needs.\n",
      "\n",
      "Market research helps companies understand customer needs and preferences which is critical in developing effective products that appeal to the target audience. By conducting market research, companies can assess the market demand for their products, identify market opportunities, and stay ahead of the competition. For example, 3M conducted extensive market research to develop Post-it notes, which turned out to be an iconic product enjoyed globally.\n",
      "\n",
      "Innovation is also essential for product development. Companies that invest in research and development to create innovative products can differentiate themselves from competitors and bring in more revenue. Apple is an excellent example of a company that has succeeded in developing innovative products - from the iPod to the iPhone to the apple watch - revolutionizing the tech industry.\n",
      "\n",
      "Risk management is another critical element of effective product development. Companies must ensure they address and manage risks associated with the development of the new product. For example, the pharmaceutical industry invests millions of dollars on R&D to develop new drugs. However, drug development involves significant risks, such as the possibility of clinical trial failure, which can lead to wasted resources.\n",
      "\n",
      "The effective development of products directly impacts customer satisfaction which eventually results in brand loyalty and contributes to the company's long-term growth and profitability. Uber’s product development strategy is an excellent example of how the company has grown by keeping the customers’ needs as a top priority. The company has continued to innovate and incorporate customers’ feedback to develop excellent customer-service and tech-oriented features.\n",
      "\n",
      "Poor product development strategies can hinder a company's growth and profitability. For example, the launch of Samsung’s Galaxy Note 7 faced significant problems due to battery issues, leading to the company suffering significant financial and reputational damage. The recall and discontinuation of the product resulted in losses amounting to $6.1 billion. Such incidents show the severe impact of inadequate product development strategies.\n",
      "\n",
      "In conclusion, a company’s ability to develop effective products can drive long-term growth and profitability. It requires adequate investment in market research, innovation, proper risk assessment and management, and catering to the customers' demand. Successful product development strategies like those implemented by 3M, Apple, and Uber have contributed significantly to their growth. On the other hand, poor product development strategies can lead to severe consequences, such as the Samsung debacle, which can hurt a company's sustainable growth prospects.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Can you provide some examples of companies that failed to develop effective products and how it impacted their growth in the long run?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Certainly, here are some examples:\n",
      "\n",
      "1. Kodak: Kodak's failure to keep up with technological advancements rendered its iconic film-based camera products obsolete. Although the company had made attempts to develop digital cameras, it was too late, and competitors such as Nikon and Canon had already taken the market share. As a result, Kodak filed for bankruptcy in 2012. 2. Blockbuster: Blockbuster's failure to adapt to the advent of streaming services such as Netflix and Hulu impacted its business that relied on renting DVDs and video tapes. Blockbuster's ill-fated late entry into the online streaming industry cost the company its market share. The company filed for bankruptcy in 2010. 3. Sears: Sears' inability to adapt to changes in consumer trends, which favored online shopping greatly impacted its sales. The company failed to provide innovative and appealing products to its customers, and its retail stores seemed outdated compared to its competitors. The company filed for bankruptcy in 2018. 4. BlackBerry: The company's initial success was based on its pioneering development of the QWERTY keyboard for smartphones. However, BlackBerry failed to keep up with the market that rapidly evolved towards touch screen options, which led to a decline in sales. BlackBerry's inability to offer desirable features and apps to its customers led to a steady decline in business, and the company filed for bankruptcy in 2015. These examples demonstrate how ineffective product development strategies can drastically impact a company's growth and profitability, pushing them to the brink of bankruptcy.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Can you give me more examples of companies that succeeded in developing effective products and how it contributed to their long-term growth and profitability?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Certainly, here are some examples of companies that have succeeded in developing effective products and how it has contributed to their long-term growth and profitability:\n",
      "\n",
      "1. Tesla: Tesla's development of electric vehicles, particularly the Model S, Model X, and Model 3, has revolutionized the automotive industry. The company's innovation in technology, as well as its dedication to sustainability and environmental responsibility, has resulted in rapid growth and profitability. For instance, in 2020, Tesla's revenue was over $31 billion, which is a staggering 36% growth rate from the previous year. 2. Amazon: Amazon's development of online shopping and the Amazon Prime subscription service has transformed the shopping industry. It's dedicated to providing seamless shopping experiences through technological and logistical innovation has driven its sustained growth and profitability. Amazon's 2020 net sales were $386 billion, demonstrating the impressive growth potential of effective product development strategies. 3. Netflix: Netflix is a company that started off as a DVD rental service before becoming a streaming giant. The company's innovative approach to content distribution and original content production has contributed to its significant growth and profitability. Its dedication to developing effective products and enhancing user experience has earned the company 204 million subscribers in over 190 countries and a net income of over $2.7 billion in 2020. 4. Spotify: Spotify's innovative music streaming service has transformed the music industry. The company's development of personalized playlists, podcasts, and integrating social media into its music sharing platform has resulted in impressive growth and profitability. Spotify's 2020 net revenue was $7.8 billion, an increase from the year before, indicating effective product development strategies. These companies illustrate how effective product development strategies can drive long-term growth and profitability when they keep up with changing customer needs, use innovative technology, and incorporate customer feedback.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Can you give me more details on how market research helps companies in effective product development?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "Certainly! Market research is critical for companies looking to develop effective products. Here are some of the ways that market research can help companies in effective product development:\n",
      "\n",
      "1. Identifying customer needs: By conducting market research, companies can identify what customers are looking for in a product. Understanding customer preferences and pain points can help companies develop products that solve their problems and meet their needs. 2. Analyzing market demand: Market research can help companies gauge market demand, assess the size of the target audience, and estimate consumer preferences. This information is particularly beneficial in developing new products as companies can evaluate the demand for a potential product, how to price the product, and market distribution channels. 3. Competitor analysis: Market research also involves analyzing the competition. Researchers can assess the strengths and weaknesses of the competition, review their product offerings, pricing, packaging, branding, and overall quality. This analysis helps in understanding the competition and identifying how to offer more value than competitors. 4. Product testing: Market research also entails product testing or market trials to evaluate the product among the target audience. Companies can obtain feedback from customers through surveys, focus groups, and interviews to gain insights into their thoughts on the product. By incorporating this information, companies can make necessary adjustments to ensure they're developing a successful and effective product. Overall, market research helps companies understand their customers, competition, and the marketplace in which they operate. Effective product development strategies require companies to consider these factors to create a product that meets customers' needs and results in sustained growth and profitability.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# Confirm the input tokens look right.\n",
    "# Note: its important that the chat template be applied.\n",
    "# Note: careful that you don't end up with 2 <|begin_of_text|> tokens!\n",
    "print(tokenizer.decode(examples[0][\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA extension not installed.\n",
      "CUDA extension not installed.\n",
      "/home/rshaw/.pyenv/versions/3.10.14/envs/auto-gptq/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.90it/s]\n"
     ]
    }
   ],
   "source": [
    "from auto_gptq import AutoGPTQForCausalLM, BaseQuantizeConfig\n",
    "\n",
    "# Setup quantization arguments.\n",
    "#   We also support speedup from 8 bits.\n",
    "#   With 8 bits, its best to set group_size=-1 (channelwise) / desc_act=False)\n",
    "quantize_config = BaseQuantizeConfig(\n",
    "    bits=4,                         # Only support 4 bit\n",
    "    group_size=128,                 # Group size 128 is typically the best spot for accuracy / performance.\n",
    "    desc_act=True,                  # Act_recordering will help accuracy.\n",
    "    model_file_base_name=\"model\",   # Name of the model.safetensors when we call save_pretrained\n",
    ")\n",
    "\n",
    "# Load model.\n",
    "model = AutoGPTQForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    quantize_config,\n",
    "    device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Start quantizing layer 1/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 1/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 1/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 1/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 1/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 1/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 1/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 1/32...\n",
      "INFO - Start quantizing layer 2/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 2/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 2/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 2/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 2/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 2/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 2/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 2/32...\n",
      "INFO - Start quantizing layer 3/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 3/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 3/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 3/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 3/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 3/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 3/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 3/32...\n",
      "INFO - Start quantizing layer 4/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 4/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 4/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 4/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 4/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 4/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 4/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 4/32...\n",
      "INFO - Start quantizing layer 5/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 5/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 5/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 5/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 5/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 5/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 5/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 5/32...\n",
      "INFO - Start quantizing layer 6/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 6/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 6/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 6/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 6/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 6/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 6/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 6/32...\n",
      "INFO - Start quantizing layer 7/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 7/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 7/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 7/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 7/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 7/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 7/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 7/32...\n",
      "INFO - Start quantizing layer 8/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 8/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 8/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 8/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 8/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 8/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 8/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 8/32...\n",
      "INFO - Start quantizing layer 9/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 9/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 9/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 9/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 9/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 9/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 9/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 9/32...\n",
      "INFO - Start quantizing layer 10/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 10/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 10/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 10/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 10/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 10/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 10/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 10/32...\n",
      "INFO - Start quantizing layer 11/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 11/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 11/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 11/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 11/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 11/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 11/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 11/32...\n",
      "INFO - Start quantizing layer 12/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 12/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 12/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 12/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 12/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 12/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 12/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 12/32...\n",
      "INFO - Start quantizing layer 13/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 13/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 13/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 13/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 13/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 13/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 13/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 13/32...\n",
      "INFO - Start quantizing layer 14/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 14/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 14/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 14/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 14/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 14/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 14/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 14/32...\n",
      "INFO - Start quantizing layer 15/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 15/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 15/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 15/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 15/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 15/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 15/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 15/32...\n",
      "INFO - Start quantizing layer 16/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 16/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 16/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 16/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 16/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 16/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 16/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 16/32...\n",
      "INFO - Start quantizing layer 17/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 17/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 17/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 17/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 17/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 17/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 17/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 17/32...\n",
      "INFO - Start quantizing layer 18/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 18/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 18/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 18/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 18/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 18/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 18/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 18/32...\n",
      "INFO - Start quantizing layer 19/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 19/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 19/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 19/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 19/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 19/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 19/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 19/32...\n",
      "INFO - Start quantizing layer 20/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 20/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 20/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 20/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 20/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 20/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 20/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 20/32...\n",
      "INFO - Start quantizing layer 21/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 21/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 21/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 21/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 21/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 21/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 21/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 21/32...\n",
      "INFO - Start quantizing layer 22/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 22/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 22/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 22/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 22/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 22/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 22/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 22/32...\n",
      "INFO - Start quantizing layer 23/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 23/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 23/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 23/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 23/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 23/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 23/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 23/32...\n",
      "INFO - Start quantizing layer 24/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 24/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 24/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 24/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 24/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 24/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 24/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 24/32...\n",
      "INFO - Start quantizing layer 25/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 25/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 25/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 25/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 25/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 25/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 25/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 25/32...\n",
      "INFO - Start quantizing layer 26/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 26/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 26/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 26/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 26/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 26/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 26/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 26/32...\n",
      "INFO - Start quantizing layer 27/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 27/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 27/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 27/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 27/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 27/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 27/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 27/32...\n",
      "INFO - Start quantizing layer 28/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 28/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 28/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 28/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 28/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 28/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 28/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 28/32...\n",
      "INFO - Start quantizing layer 29/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 29/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 29/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 29/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 29/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 29/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 29/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 29/32...\n",
      "INFO - Start quantizing layer 30/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 30/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 30/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 30/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 30/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 30/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 30/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 30/32...\n",
      "INFO - Start quantizing layer 31/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 31/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 31/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 31/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 31/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 31/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 31/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 31/32...\n",
      "INFO - Start quantizing layer 32/32\n",
      "INFO - Quantizing self_attn.k_proj in layer 32/32...\n",
      "INFO - Quantizing self_attn.v_proj in layer 32/32...\n",
      "INFO - Quantizing self_attn.q_proj in layer 32/32...\n",
      "INFO - Quantizing self_attn.o_proj in layer 32/32...\n",
      "INFO - Quantizing mlp.up_proj in layer 32/32...\n",
      "INFO - Quantizing mlp.gate_proj in layer 32/32...\n",
      "INFO - Quantizing mlp.down_proj in layer 32/32...\n"
     ]
    }
   ],
   "source": [
    "# Apply the GPTQ algorithm.\n",
    "model.quantize(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - you are using save_pretrained, which will re-direct to save_quantized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving gptq model to Meta-Llama-3-8B-Instruct-gptq\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Meta-Llama-3-8B-Instruct-gptq/tokenizer_config.json',\n",
       " 'Meta-Llama-3-8B-Instruct-gptq/special_tokens_map.json',\n",
       " 'Meta-Llama-3-8B-Instruct-gptq/tokenizer.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gptq_save_dir = f\"{MODEL_ID.split('/')[-1]}-gptq\"\n",
    "print(f\"Saving gptq model to {gptq_save_dir}\")\n",
    "model.save_pretrained(gptq_save_dir)\n",
    "tokenizer.save_pretrained(gptq_save_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto-gptq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
