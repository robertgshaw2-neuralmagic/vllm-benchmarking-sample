{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SmoothQuant with `meta-llama/Meta-Llama-3-8B-Instruct`\n",
    "\n",
    "In this tutorial, we will demonstrate how to apply SmoothQuant to Llama-3-8B instruct to quantize the weights and activations to int8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=6\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install\n",
    "\n",
    "Get started by installing SparseML via pip. You will need a GPU instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sparseml[transformers]==1.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Load Model\n",
    "\n",
    "First, load a model from the Hugging Face hub (in this case `Meta-Llama-3-8B-Instruct`) using `SparseAutoModelForCausalLM`.\n",
    "\n",
    "* `SparseAutoModelForCausalLM` is a wrapper around `AutoModelForCausalLM`, with some added utilities for saving and loading quantized models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msparseml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseAutoModelForCausalLM\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sparseml.transformers import SparseAutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "MODEL_ID = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "model = SparseAutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Dataset\n",
    "\n",
    "Next, load a dataset for calibrating the model. \n",
    "\n",
    "Best practices for calibration data:\n",
    "* Apply the model's chat template to the sample data\n",
    "* Use at least 512 samples. 1024 samples can improve the results sometimes\n",
    "* Use at least 2048 sequence length. 4096 can improve the results sometimes\n",
    "* Select a diverse, high quality dataset (ideally that is adapted to your use case)\n",
    "\n",
    "In this case, we will use the [`HuggingFaceH4/ultrachat_200k` dataset](https://huggingface.co/datasets/HuggingFaceH4/ultrachat_200k), which contains multi-turn conversations and is generally a good choice for chat models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 512/512 [00:00<00:00, 4314.95 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "NUM_CALIBRATION_SAMPLES = 512\n",
    "\n",
    "ds = load_dataset(\"HuggingFaceH4/ultrachat_200k\", split=\"train_sft\")\n",
    "ds = ds.shuffle(seed=42).select(range(NUM_CALIBRATION_SAMPLES))\n",
    "\n",
    "# Dataset should have \"text\" field with the data you want to use to calibrate\n",
    "ds = ds.map(lambda batch: {\n",
    "    \"text\": tokenizer.apply_chat_template(batch[\"messages\"], tokenize=False)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Recipe\n",
    "\n",
    "Next, we make a recipe to specify the quantization algorithm to apply. \n",
    "\n",
    "XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe = \"\"\"\n",
    "quant_stage:\n",
    "    quant_modifiers:\n",
    "        SmoothQuantModifier:\n",
    "            smoothing_strength: 0.5\n",
    "            mappings: [\n",
    "                [[\"re:.*q_proj\", \"re:.*k_proj\", \"re:.*v_proj\"], \"re:.*input_layernorm\"],\n",
    "                [[\"re:.*gate_proj\", \"re:.*up_proj\"], \"re:.*post_attention_layernorm\"]\n",
    "            ]\n",
    "        GPTQModifier:\n",
    "            sequential_update: false\n",
    "            ignore: [\"lm_head\"]\n",
    "            config_groups:\n",
    "                group_0:\n",
    "                    weights:\n",
    "                        num_bits: 8\n",
    "                        type: \"int\"\n",
    "                        symmetric: true\n",
    "                        strategy: \"channel\"\n",
    "                    input_activations:\n",
    "                        num_bits: 8\n",
    "                        type: \"int\"\n",
    "                        symmetric: true\n",
    "                        strategy: \"tensor\"\n",
    "                    targets: [\"Linear\"]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Apply The Algorithm\n",
    "\n",
    "After making the recipe, we can apply the quantization algorithm using the `oneshot` function.\n",
    "\n",
    "> WARNING: You will need about 60GB of GPU RAM to run the below. To reduce memory consumption at the expense of speed, set `sequential_update: true` in your recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 02:29:14 sparseml.transformers.finetune.text_generation WARNING  Process rank: 0, device: cuda:0, n_gpu: 8, distributed training: True, 16-bits training: False\n",
      "Logging all SparseML modifier-level logs to sparse_logs/12-06-2024_02.29.14.log\n",
      "2024-06-12 02:29:14 sparseml.core.logger.logger INFO     Logging all SparseML modifier-level logs to sparse_logs/12-06-2024_02.29.14.log\n",
      "Removing unneeded columns: 100%|██████████| 512/512 [00:00<00:00, 119577.02 examples/s]\n",
      "Running tokenizer on dataset: 100%|██████████| 512/512 [00:00<00:00, 1437.90 examples/s]\n",
      "Adding labels: 100%|██████████| 512/512 [00:00<00:00, 669.01 examples/s]\n",
      "2024-06-12 02:29:16 sparseml.transformers.finetune.runner INFO     *** One Shot ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_ids', 'attention_mask', 'labels']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 02:29:16 sparseml.core.recipe.recipe WARNING  Could not process input as a file path or zoo stub, attempting to process it as a string.\n",
      "/home/rshaw/.pyenv/versions/3.10.14/envs/sparseml-env/lib/python3.10/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_fuse_fn_name\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home/rshaw/.pyenv/versions/3.10.14/envs/sparseml-env/lib/python3.10/site-packages/pydantic/_internal/_fields.py:160: UserWarning: Field \"model_fuse_fn_kwargs\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "2024-06-12 02:29:17 sparseml.modifiers.smoothquant.pytorch INFO     Running SmoothQuantModifier calibration with 512 samples...\n",
      "100%|██████████| 512/512 [00:33<00:00, 15.22it/s]\n",
      "2024-06-12 02:29:50 sparseml.modifiers.smoothquant.pytorch INFO     Smoothing activation scales...\n",
      "2024-06-12 02:29:50 sparseml.modifiers.quantization.gptq.base WARNING  GPTQ quantization is set to True without an active quantization modifier.\n",
      "2024-06-12 02:29:50 sparseml.modifiers.quantization.gptq.base INFO     Building quantization modifier with args: {'config_groups': {'group_0': QuantizationScheme(targets=['Linear'], weights=QuantizationArgs(num_bits=8, type=<QuantizationType.INT: 'int'>, symmetric=True, group_size=None, strategy=<QuantizationStrategy.CHANNEL: 'channel'>, block_structure=None, dynamic=False, observer='minmax', observer_kwargs={}), input_activations=QuantizationArgs(num_bits=8, type=<QuantizationType.INT: 'int'>, symmetric=True, group_size=None, strategy=<QuantizationStrategy.TENSOR: 'tensor'>, block_structure=None, dynamic=False, observer='minmax', observer_kwargs={}), output_activations=None)}, 'ignore': ['lm_head']}\n",
      "2024-06-12 02:29:50 sparseml.modifiers.quantization.quantization.pytorch INFO     Running QuantizationModifier calibration with 512 samples...\n",
      "100%|██████████| 512/512 [01:26<00:00,  5.91it/s]\n",
      "2024-06-12 02:31:17 sparseml.modifiers.quantization.gptq.pytorch INFO     Preparing model.layers.0 for compression\n",
      "2024-06-12 02:31:17 sparseml.modifiers.quantization.gptq.pytorch INFO     Preparing model.layers.1 for compression\n",
      "2024-06-12 02:31:17 sparseml.modifiers.quantization.gptq.pytorch INFO     Preparing model.layers.2 for compression\n",
      "2024-06-12 02:31:17 sparseml.modifiers.quantization.gptq.pytorch INFO     Preparing model.layers.3 for compression\n",
      "2024-06-12 02:31:17 sparseml.modifiers.quantization.gptq.pytorch INFO     Preparing model.layers.4 for compression\n",
      "2024-06-12 02:31:17 sparseml.modifiers.quantization.gptq.pytorch INFO     Preparing model.layers.5 for compression\n",
      "2024-06-12 02:31:17 sparseml.modifiers.quantization.gptq.pytorch INFO     Preparing model.layers.6 for compression\n",
      "2024-06-12 02:31:17 sparseml.modifiers.quantization.gptq.pytorch INFO     Preparing model.layers.7 for compression\n",
      "2024-06-12 02:31:17 sparseml.modifiers.quantization.gptq.pytorch INFO     Preparing model.layers.8 for compression\n",
      "2024-06-12 02:31:17 sparseml.modifiers.quantization.gptq.pytorch INFO     Preparing model.layers.9 for compression\n",
      "2024-06-12 02:31:17 sparseml.modifiers.quantization.gptq.pytorch INFO     Preparing model.layers.10 for compression\n",
      "2024-06-12 02:31:17 sparseml.modifiers.quantization.gptq.pytorch INFO     Preparing model.layers.11 for compression\n",
      "2024-06-12 02:31:17 sparseml.modifiers.quantization.gptq.pytorch INFO     Preparing model.layers.12 for compression\n",
      "2024-06-12 02:31:17 sparseml.modifiers.quantization.gptq.pytorch INFO     Preparing model.layers.13 for compression\n",
      "2024-06-12 02:31:17 sparseml.modifiers.quantization.gptq.pytorch INFO     Preparing model.layers.14 for compression\n",
      "2024-06-12 02:31:17 sparseml.modifiers.quantization.gptq.pytorch INFO     Preparing model.layers.15 for compression\n",
      "2024-06-12 02:31:17 sparseml.modifiers.quantization.gptq.pytorch INFO     Preparing model.layers.16 for compression\n",
      "2024-06-12 02:31:17 sparseml.modifiers.quantization.gptq.pytorch INFO     Preparing model.layers.17 for compression\n",
      "2024-06-12 02:31:17 sparseml.modifiers.quantization.gptq.pytorch INFO     Preparing model.layers.18 for compression\n",
      "2024-06-12 02:31:17 sparseml.modifiers.quantization.gptq.pytorch INFO     Preparing model.layers.19 for compression\n",
      "2024-06-12 02:31:17 sparseml.modifiers.quantization.gptq.pytorch INFO     Preparing model.layers.20 for compression\n",
      "2024-06-12 02:31:17 sparseml.modifiers.quantization.gptq.pytorch INFO     Preparing model.layers.21 for compression\n",
      "2024-06-12 02:31:17 sparseml.modifiers.quantization.gptq.pytorch INFO     Running GPTQModifier calibration with 512 samples...\n",
      "100%|██████████| 512/512 [04:03<00:00,  2.11it/s]\n",
      "2024-06-12 02:35:20 sparseml.modifiers.quantization.gptq.pytorch INFO     \n",
      "===== Compressing layer 1/22  =====\n",
      "2024-06-12 02:35:20 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.0.model.layers.0.self_attn.q_proj...\n",
      "2024-06-12 02:35:21 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.50\n",
      "2024-06-12 02:35:21 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 1.40\n",
      "2024-06-12 02:35:21 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.0.model.layers.0.self_attn.k_proj...\n",
      "2024-06-12 02:35:21 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.42\n",
      "2024-06-12 02:35:21 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 1.51\n",
      "2024-06-12 02:35:21 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.0.model.layers.0.self_attn.v_proj...\n",
      "2024-06-12 02:35:22 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.42\n",
      "2024-06-12 02:35:22 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.00\n",
      "2024-06-12 02:35:22 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.0.model.layers.0.self_attn.o_proj...\n",
      "2024-06-12 02:35:22 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.42\n",
      "2024-06-12 02:35:22 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.00\n",
      "2024-06-12 02:35:22 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.0.model.layers.0.mlp.gate_proj...\n",
      "2024-06-12 02:35:22 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.42\n",
      "2024-06-12 02:35:22 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 3.50\n",
      "2024-06-12 02:35:22 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.0.model.layers.0.mlp.up_proj...\n",
      "2024-06-12 02:35:23 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.42\n",
      "2024-06-12 02:35:23 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 1.47\n",
      "2024-06-12 02:35:23 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.0.model.layers.0.mlp.down_proj...\n",
      "2024-06-12 02:35:24 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 1.17\n",
      "2024-06-12 02:35:24 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.00\n",
      "2024-06-12 02:35:24 sparseml.modifiers.quantization.gptq.pytorch INFO     \n",
      "===== Compressing layer 2/22  =====\n",
      "2024-06-12 02:35:24 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.1.model.layers.1.self_attn.q_proj...\n",
      "2024-06-12 02:35:25 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.47\n",
      "2024-06-12 02:35:25 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 4.96\n",
      "2024-06-12 02:35:25 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.1.model.layers.1.self_attn.k_proj...\n",
      "2024-06-12 02:35:25 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.43\n",
      "2024-06-12 02:35:25 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 3.57\n",
      "2024-06-12 02:35:25 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.1.model.layers.1.self_attn.v_proj...\n",
      "2024-06-12 02:35:25 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.43\n",
      "2024-06-12 02:35:25 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.02\n",
      "2024-06-12 02:35:25 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.1.model.layers.1.self_attn.o_proj...\n",
      "2024-06-12 02:35:26 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.43\n",
      "2024-06-12 02:35:26 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.00\n",
      "2024-06-12 02:35:26 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.1.model.layers.1.mlp.gate_proj...\n",
      "2024-06-12 02:35:26 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:26 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 2.58\n",
      "2024-06-12 02:35:26 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.1.model.layers.1.mlp.up_proj...\n",
      "2024-06-12 02:35:27 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:27 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 2.06\n",
      "2024-06-12 02:35:27 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.1.model.layers.1.mlp.down_proj...\n",
      "2024-06-12 02:35:28 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 1.23\n",
      "2024-06-12 02:35:28 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.01\n",
      "2024-06-12 02:35:28 sparseml.modifiers.quantization.gptq.pytorch INFO     \n",
      "===== Compressing layer 3/22  =====\n",
      "2024-06-12 02:35:28 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.2.model.layers.2.self_attn.q_proj...\n",
      "2024-06-12 02:35:28 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.43\n",
      "2024-06-12 02:35:28 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 7.22\n",
      "2024-06-12 02:35:28 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.2.model.layers.2.self_attn.k_proj...\n",
      "2024-06-12 02:35:29 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.43\n",
      "2024-06-12 02:35:29 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 5.14\n",
      "2024-06-12 02:35:29 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.2.model.layers.2.self_attn.v_proj...\n",
      "2024-06-12 02:35:29 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:29 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.03\n",
      "2024-06-12 02:35:29 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.2.model.layers.2.self_attn.o_proj...\n",
      "2024-06-12 02:35:30 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.43\n",
      "2024-06-12 02:35:30 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.01\n",
      "2024-06-12 02:35:30 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.2.model.layers.2.mlp.gate_proj...\n",
      "2024-06-12 02:35:30 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:30 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 5.85\n",
      "2024-06-12 02:35:30 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.2.model.layers.2.mlp.up_proj...\n",
      "2024-06-12 02:35:31 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:31 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 5.39\n",
      "2024-06-12 02:35:31 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.2.model.layers.2.mlp.down_proj...\n",
      "2024-06-12 02:35:32 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 1.22\n",
      "2024-06-12 02:35:32 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.14\n",
      "2024-06-12 02:35:32 sparseml.modifiers.quantization.gptq.pytorch INFO     \n",
      "===== Compressing layer 4/22  =====\n",
      "2024-06-12 02:35:32 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.3.model.layers.3.self_attn.q_proj...\n",
      "2024-06-12 02:35:32 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.43\n",
      "2024-06-12 02:35:32 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 14.84\n",
      "2024-06-12 02:35:32 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.3.model.layers.3.self_attn.k_proj...\n",
      "2024-06-12 02:35:33 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:33 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 7.36\n",
      "2024-06-12 02:35:33 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.3.model.layers.3.self_attn.v_proj...\n",
      "2024-06-12 02:35:33 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:33 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.15\n",
      "2024-06-12 02:35:33 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.3.model.layers.3.self_attn.o_proj...\n",
      "2024-06-12 02:35:34 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:34 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.00\n",
      "2024-06-12 02:35:34 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.3.model.layers.3.mlp.gate_proj...\n",
      "2024-06-12 02:35:34 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:34 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 4.24\n",
      "2024-06-12 02:35:34 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.3.model.layers.3.mlp.up_proj...\n",
      "2024-06-12 02:35:34 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:34 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 3.67\n",
      "2024-06-12 02:35:34 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.3.model.layers.3.mlp.down_proj...\n",
      "2024-06-12 02:35:36 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 1.24\n",
      "2024-06-12 02:35:36 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.02\n",
      "2024-06-12 02:35:36 sparseml.modifiers.quantization.gptq.pytorch INFO     \n",
      "===== Compressing layer 5/22  =====\n",
      "2024-06-12 02:35:36 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.4.model.layers.4.self_attn.q_proj...\n",
      "2024-06-12 02:35:36 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:36 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 25.90\n",
      "2024-06-12 02:35:36 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.4.model.layers.4.self_attn.k_proj...\n",
      "2024-06-12 02:35:37 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:37 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 14.86\n",
      "2024-06-12 02:35:37 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.4.model.layers.4.self_attn.v_proj...\n",
      "2024-06-12 02:35:37 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:37 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.28\n",
      "2024-06-12 02:35:37 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.4.model.layers.4.self_attn.o_proj...\n",
      "2024-06-12 02:35:37 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:37 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.01\n",
      "2024-06-12 02:35:37 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.4.model.layers.4.mlp.gate_proj...\n",
      "2024-06-12 02:35:38 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:38 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 6.80\n",
      "2024-06-12 02:35:38 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.4.model.layers.4.mlp.up_proj...\n",
      "2024-06-12 02:35:38 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:38 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 5.80\n",
      "2024-06-12 02:35:38 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.4.model.layers.4.mlp.down_proj...\n",
      "2024-06-12 02:35:40 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 1.24\n",
      "2024-06-12 02:35:40 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.04\n",
      "2024-06-12 02:35:40 sparseml.modifiers.quantization.gptq.pytorch INFO     \n",
      "===== Compressing layer 6/22  =====\n",
      "2024-06-12 02:35:40 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.5.model.layers.5.self_attn.q_proj...\n",
      "2024-06-12 02:35:40 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.47\n",
      "2024-06-12 02:35:40 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 22.68\n",
      "2024-06-12 02:35:40 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.5.model.layers.5.self_attn.k_proj...\n",
      "2024-06-12 02:35:40 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:40 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 12.24\n",
      "2024-06-12 02:35:40 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.5.model.layers.5.self_attn.v_proj...\n",
      "2024-06-12 02:35:41 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:41 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.33\n",
      "2024-06-12 02:35:41 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.5.model.layers.5.self_attn.o_proj...\n",
      "2024-06-12 02:35:41 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:41 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.02\n",
      "2024-06-12 02:35:41 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.5.model.layers.5.mlp.gate_proj...\n",
      "2024-06-12 02:35:42 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:42 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 9.70\n",
      "2024-06-12 02:35:42 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.5.model.layers.5.mlp.up_proj...\n",
      "2024-06-12 02:35:42 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:42 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 8.04\n",
      "2024-06-12 02:35:42 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.5.model.layers.5.mlp.down_proj...\n",
      "2024-06-12 02:35:44 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 1.25\n",
      "2024-06-12 02:35:44 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.08\n",
      "2024-06-12 02:35:44 sparseml.modifiers.quantization.gptq.pytorch INFO     \n",
      "===== Compressing layer 7/22  =====\n",
      "2024-06-12 02:35:44 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.6.model.layers.6.self_attn.q_proj...\n",
      "2024-06-12 02:35:44 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:44 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 29.75\n",
      "2024-06-12 02:35:44 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.6.model.layers.6.self_attn.k_proj...\n",
      "2024-06-12 02:35:44 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:44 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 13.80\n",
      "2024-06-12 02:35:44 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.6.model.layers.6.self_attn.v_proj...\n",
      "2024-06-12 02:35:45 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:45 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.31\n",
      "2024-06-12 02:35:45 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.6.model.layers.6.self_attn.o_proj...\n",
      "2024-06-12 02:35:45 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:45 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.03\n",
      "2024-06-12 02:35:45 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.6.model.layers.6.mlp.gate_proj...\n",
      "2024-06-12 02:35:46 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:35:46 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 12.46\n",
      "2024-06-12 02:35:46 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.6.model.layers.6.mlp.up_proj...\n",
      "2024-06-12 02:35:46 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:46 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 9.73\n",
      "2024-06-12 02:35:46 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.6.model.layers.6.mlp.down_proj...\n",
      "2024-06-12 02:35:47 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 1.25\n",
      "2024-06-12 02:35:47 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.12\n",
      "2024-06-12 02:35:47 sparseml.modifiers.quantization.gptq.pytorch INFO     \n",
      "===== Compressing layer 8/22  =====\n",
      "2024-06-12 02:35:47 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.7.model.layers.7.self_attn.q_proj...\n",
      "2024-06-12 02:35:48 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:48 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 45.31\n",
      "2024-06-12 02:35:48 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.7.model.layers.7.self_attn.k_proj...\n",
      "2024-06-12 02:35:48 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:48 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 16.85\n",
      "2024-06-12 02:35:48 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.7.model.layers.7.self_attn.v_proj...\n",
      "2024-06-12 02:35:49 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:49 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.54\n",
      "2024-06-12 02:35:49 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.7.model.layers.7.self_attn.o_proj...\n",
      "2024-06-12 02:35:49 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:49 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.05\n",
      "2024-06-12 02:35:49 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.7.model.layers.7.mlp.gate_proj...\n",
      "2024-06-12 02:35:50 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:50 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 17.96\n",
      "2024-06-12 02:35:50 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.7.model.layers.7.mlp.up_proj...\n",
      "2024-06-12 02:35:50 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:50 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 12.01\n",
      "2024-06-12 02:35:50 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.7.model.layers.7.mlp.down_proj...\n",
      "2024-06-12 02:35:51 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 1.24\n",
      "2024-06-12 02:35:51 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.56\n",
      "2024-06-12 02:35:51 sparseml.modifiers.quantization.gptq.pytorch INFO     \n",
      "===== Compressing layer 9/22  =====\n",
      "2024-06-12 02:35:51 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.8.model.layers.8.self_attn.q_proj...\n",
      "2024-06-12 02:35:52 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:52 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 47.50\n",
      "2024-06-12 02:35:52 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.8.model.layers.8.self_attn.k_proj...\n",
      "2024-06-12 02:35:52 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:52 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 24.12\n",
      "2024-06-12 02:35:52 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.8.model.layers.8.self_attn.v_proj...\n",
      "2024-06-12 02:35:53 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:53 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.58\n",
      "2024-06-12 02:35:53 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.8.model.layers.8.self_attn.o_proj...\n",
      "2024-06-12 02:35:53 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:53 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.08\n",
      "2024-06-12 02:35:53 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.8.model.layers.8.mlp.gate_proj...\n",
      "2024-06-12 02:35:54 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:54 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 14.85\n",
      "2024-06-12 02:35:54 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.8.model.layers.8.mlp.up_proj...\n",
      "2024-06-12 02:35:54 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:54 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 10.95\n",
      "2024-06-12 02:35:54 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.8.model.layers.8.mlp.down_proj...\n",
      "2024-06-12 02:35:55 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 1.25\n",
      "2024-06-12 02:35:55 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.24\n",
      "2024-06-12 02:35:55 sparseml.modifiers.quantization.gptq.pytorch INFO     \n",
      "===== Compressing layer 10/22  =====\n",
      "2024-06-12 02:35:55 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.9.model.layers.9.self_attn.q_proj...\n",
      "2024-06-12 02:35:56 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.47\n",
      "2024-06-12 02:35:56 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 26.21\n",
      "2024-06-12 02:35:56 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.9.model.layers.9.self_attn.k_proj...\n",
      "2024-06-12 02:35:56 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:56 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 12.60\n",
      "2024-06-12 02:35:56 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.9.model.layers.9.self_attn.v_proj...\n",
      "2024-06-12 02:35:57 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:57 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.36\n",
      "2024-06-12 02:35:57 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.9.model.layers.9.self_attn.o_proj...\n",
      "2024-06-12 02:35:57 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:57 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.04\n",
      "2024-06-12 02:35:57 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.9.model.layers.9.mlp.gate_proj...\n",
      "2024-06-12 02:35:57 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:57 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 17.89\n",
      "2024-06-12 02:35:57 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.9.model.layers.9.mlp.up_proj...\n",
      "2024-06-12 02:35:58 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:35:58 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 12.06\n",
      "2024-06-12 02:35:58 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.9.model.layers.9.mlp.down_proj...\n",
      "2024-06-12 02:35:59 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 1.24\n",
      "2024-06-12 02:35:59 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.21\n",
      "2024-06-12 02:35:59 sparseml.modifiers.quantization.gptq.pytorch INFO     \n",
      "===== Compressing layer 11/22  =====\n",
      "2024-06-12 02:35:59 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.10.model.layers.10.self_attn.q_proj...\n",
      "2024-06-12 02:36:00 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:36:00 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 32.07\n",
      "2024-06-12 02:36:00 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.10.model.layers.10.self_attn.k_proj...\n",
      "2024-06-12 02:36:00 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:36:00 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 15.57\n",
      "2024-06-12 02:36:00 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.10.model.layers.10.self_attn.v_proj...\n",
      "2024-06-12 02:36:00 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:36:00 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.45\n",
      "2024-06-12 02:36:00 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.10.model.layers.10.self_attn.o_proj...\n",
      "2024-06-12 02:36:01 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:36:01 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.04\n",
      "2024-06-12 02:36:01 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.10.model.layers.10.mlp.gate_proj...\n",
      "2024-06-12 02:36:01 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:01 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 19.46\n",
      "2024-06-12 02:36:01 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.10.model.layers.10.mlp.up_proj...\n",
      "2024-06-12 02:36:02 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:36:02 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 13.99\n",
      "2024-06-12 02:36:02 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.10.model.layers.10.mlp.down_proj...\n",
      "2024-06-12 02:36:03 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 1.24\n",
      "2024-06-12 02:36:03 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.25\n",
      "2024-06-12 02:36:03 sparseml.modifiers.quantization.gptq.pytorch INFO     \n",
      "===== Compressing layer 12/22  =====\n",
      "2024-06-12 02:36:03 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.11.model.layers.11.self_attn.q_proj...\n",
      "2024-06-12 02:36:03 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:36:03 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 53.19\n",
      "2024-06-12 02:36:03 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.11.model.layers.11.self_attn.k_proj...\n",
      "2024-06-12 02:36:04 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:36:04 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 18.94\n",
      "2024-06-12 02:36:04 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.11.model.layers.11.self_attn.v_proj...\n",
      "2024-06-12 02:36:04 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:36:04 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.63\n",
      "2024-06-12 02:36:04 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.11.model.layers.11.self_attn.o_proj...\n",
      "2024-06-12 02:36:05 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:36:05 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.09\n",
      "2024-06-12 02:36:05 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.11.model.layers.11.mlp.gate_proj...\n",
      "2024-06-12 02:36:05 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:36:05 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 24.77\n",
      "2024-06-12 02:36:05 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.11.model.layers.11.mlp.up_proj...\n",
      "2024-06-12 02:36:06 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:36:06 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 17.52\n",
      "2024-06-12 02:36:06 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.11.model.layers.11.mlp.down_proj...\n",
      "2024-06-12 02:36:07 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 1.24\n",
      "2024-06-12 02:36:07 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.34\n",
      "2024-06-12 02:36:07 sparseml.modifiers.quantization.gptq.pytorch INFO     \n",
      "===== Compressing layer 13/22  =====\n",
      "2024-06-12 02:36:07 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.12.model.layers.12.self_attn.q_proj...\n",
      "2024-06-12 02:36:07 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:36:07 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 43.87\n",
      "2024-06-12 02:36:07 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.12.model.layers.12.self_attn.k_proj...\n",
      "2024-06-12 02:36:08 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:36:08 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 21.96\n",
      "2024-06-12 02:36:08 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.12.model.layers.12.self_attn.v_proj...\n",
      "2024-06-12 02:36:08 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:36:08 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.82\n",
      "2024-06-12 02:36:08 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.12.model.layers.12.self_attn.o_proj...\n",
      "2024-06-12 02:36:09 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:36:09 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.11\n",
      "2024-06-12 02:36:09 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.12.model.layers.12.mlp.gate_proj...\n",
      "2024-06-12 02:36:09 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:36:09 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 35.27\n",
      "2024-06-12 02:36:09 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.12.model.layers.12.mlp.up_proj...\n",
      "2024-06-12 02:36:10 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.44\n",
      "2024-06-12 02:36:10 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 21.26\n",
      "2024-06-12 02:36:10 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.12.model.layers.12.mlp.down_proj...\n",
      "2024-06-12 02:36:11 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 1.24\n",
      "2024-06-12 02:36:11 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.51\n",
      "2024-06-12 02:36:11 sparseml.modifiers.quantization.gptq.pytorch INFO     \n",
      "===== Compressing layer 14/22  =====\n",
      "2024-06-12 02:36:11 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.13.model.layers.13.self_attn.q_proj...\n",
      "2024-06-12 02:36:11 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.48\n",
      "2024-06-12 02:36:11 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 50.46\n",
      "2024-06-12 02:36:11 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.13.model.layers.13.self_attn.k_proj...\n",
      "2024-06-12 02:36:12 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:12 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 23.26\n",
      "2024-06-12 02:36:12 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.13.model.layers.13.self_attn.v_proj...\n",
      "2024-06-12 02:36:12 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:12 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.81\n",
      "2024-06-12 02:36:12 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.13.model.layers.13.self_attn.o_proj...\n",
      "2024-06-12 02:36:13 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:13 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.13\n",
      "2024-06-12 02:36:13 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.13.model.layers.13.mlp.gate_proj...\n",
      "2024-06-12 02:36:13 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:13 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 38.91\n",
      "2024-06-12 02:36:13 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.13.model.layers.13.mlp.up_proj...\n",
      "2024-06-12 02:36:14 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:14 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 24.35\n",
      "2024-06-12 02:36:14 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.13.model.layers.13.mlp.down_proj...\n",
      "2024-06-12 02:36:15 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 1.27\n",
      "2024-06-12 02:36:15 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.69\n",
      "2024-06-12 02:36:15 sparseml.modifiers.quantization.gptq.pytorch INFO     \n",
      "===== Compressing layer 15/22  =====\n",
      "2024-06-12 02:36:15 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.14.model.layers.14.self_attn.q_proj...\n",
      "2024-06-12 02:36:15 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:15 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 50.83\n",
      "2024-06-12 02:36:15 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.14.model.layers.14.self_attn.k_proj...\n",
      "2024-06-12 02:36:16 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:16 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 23.64\n",
      "2024-06-12 02:36:16 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.14.model.layers.14.self_attn.v_proj...\n",
      "2024-06-12 02:36:16 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:16 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 1.10\n",
      "2024-06-12 02:36:16 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.14.model.layers.14.self_attn.o_proj...\n",
      "2024-06-12 02:36:17 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:17 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.38\n",
      "2024-06-12 02:36:17 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.14.model.layers.14.mlp.gate_proj...\n",
      "2024-06-12 02:36:17 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.46\n",
      "2024-06-12 02:36:17 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 41.79\n",
      "2024-06-12 02:36:17 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.14.model.layers.14.mlp.up_proj...\n",
      "2024-06-12 02:36:18 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:18 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 28.42\n",
      "2024-06-12 02:36:18 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.14.model.layers.14.mlp.down_proj...\n",
      "2024-06-12 02:36:19 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 1.27\n",
      "2024-06-12 02:36:19 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.84\n",
      "2024-06-12 02:36:19 sparseml.modifiers.quantization.gptq.pytorch INFO     \n",
      "===== Compressing layer 16/22  =====\n",
      "2024-06-12 02:36:19 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.15.model.layers.15.self_attn.q_proj...\n",
      "2024-06-12 02:36:19 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:19 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 66.42\n",
      "2024-06-12 02:36:19 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.15.model.layers.15.self_attn.k_proj...\n",
      "2024-06-12 02:36:20 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:20 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 27.86\n",
      "2024-06-12 02:36:20 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.15.model.layers.15.self_attn.v_proj...\n",
      "2024-06-12 02:36:20 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:20 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 2.18\n",
      "2024-06-12 02:36:20 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.15.model.layers.15.self_attn.o_proj...\n",
      "2024-06-12 02:36:21 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:21 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.33\n",
      "2024-06-12 02:36:21 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.15.model.layers.15.mlp.gate_proj...\n",
      "2024-06-12 02:36:21 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:21 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 45.96\n",
      "2024-06-12 02:36:21 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.15.model.layers.15.mlp.up_proj...\n",
      "2024-06-12 02:36:22 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:22 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 31.74\n",
      "2024-06-12 02:36:22 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.15.model.layers.15.mlp.down_proj...\n",
      "2024-06-12 02:36:23 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 1.27\n",
      "2024-06-12 02:36:23 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 1.34\n",
      "2024-06-12 02:36:23 sparseml.modifiers.quantization.gptq.pytorch INFO     \n",
      "===== Compressing layer 17/22  =====\n",
      "2024-06-12 02:36:23 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.16.model.layers.16.self_attn.q_proj...\n",
      "2024-06-12 02:36:23 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:23 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 67.94\n",
      "2024-06-12 02:36:23 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.16.model.layers.16.self_attn.k_proj...\n",
      "2024-06-12 02:36:24 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:24 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 30.21\n",
      "2024-06-12 02:36:24 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.16.model.layers.16.self_attn.v_proj...\n",
      "2024-06-12 02:36:24 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:24 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 1.47\n",
      "2024-06-12 02:36:24 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.16.model.layers.16.self_attn.o_proj...\n",
      "2024-06-12 02:36:25 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:25 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.34\n",
      "2024-06-12 02:36:25 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.16.model.layers.16.mlp.gate_proj...\n",
      "2024-06-12 02:36:25 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:25 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 63.57\n",
      "2024-06-12 02:36:25 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.16.model.layers.16.mlp.up_proj...\n",
      "2024-06-12 02:36:26 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:26 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 39.64\n",
      "2024-06-12 02:36:26 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.16.model.layers.16.mlp.down_proj...\n",
      "2024-06-12 02:36:27 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 1.27\n",
      "2024-06-12 02:36:27 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 2.05\n",
      "2024-06-12 02:36:27 sparseml.modifiers.quantization.gptq.pytorch INFO     \n",
      "===== Compressing layer 18/22  =====\n",
      "2024-06-12 02:36:27 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.17.model.layers.17.self_attn.q_proj...\n",
      "2024-06-12 02:36:27 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.48\n",
      "2024-06-12 02:36:27 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 68.43\n",
      "2024-06-12 02:36:27 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.17.model.layers.17.self_attn.k_proj...\n",
      "2024-06-12 02:36:28 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:28 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 29.19\n",
      "2024-06-12 02:36:28 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.17.model.layers.17.self_attn.v_proj...\n",
      "2024-06-12 02:36:28 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:28 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 3.78\n",
      "2024-06-12 02:36:28 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.17.model.layers.17.self_attn.o_proj...\n",
      "2024-06-12 02:36:29 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:29 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.60\n",
      "2024-06-12 02:36:29 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.17.model.layers.17.mlp.gate_proj...\n",
      "2024-06-12 02:36:29 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:29 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 68.87\n",
      "2024-06-12 02:36:29 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.17.model.layers.17.mlp.up_proj...\n",
      "2024-06-12 02:36:30 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:30 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 47.45\n",
      "2024-06-12 02:36:30 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.17.model.layers.17.mlp.down_proj...\n",
      "2024-06-12 02:36:31 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 1.27\n",
      "2024-06-12 02:36:31 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 2.26\n",
      "2024-06-12 02:36:31 sparseml.modifiers.quantization.gptq.pytorch INFO     \n",
      "===== Compressing layer 19/22  =====\n",
      "2024-06-12 02:36:31 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.18.model.layers.18.self_attn.q_proj...\n",
      "2024-06-12 02:36:31 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:31 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 76.69\n",
      "2024-06-12 02:36:31 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.18.model.layers.18.self_attn.k_proj...\n",
      "2024-06-12 02:36:32 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:32 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 41.12\n",
      "2024-06-12 02:36:32 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.18.model.layers.18.self_attn.v_proj...\n",
      "2024-06-12 02:36:32 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:32 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 7.81\n",
      "2024-06-12 02:36:32 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.18.model.layers.18.self_attn.o_proj...\n",
      "2024-06-12 02:36:33 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:33 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.74\n",
      "2024-06-12 02:36:33 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.18.model.layers.18.mlp.gate_proj...\n",
      "2024-06-12 02:36:33 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:33 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 84.61\n",
      "2024-06-12 02:36:33 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.18.model.layers.18.mlp.up_proj...\n",
      "2024-06-12 02:36:34 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:34 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 58.39\n",
      "2024-06-12 02:36:34 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.18.model.layers.18.mlp.down_proj...\n",
      "2024-06-12 02:36:35 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 1.27\n",
      "2024-06-12 02:36:35 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 3.61\n",
      "2024-06-12 02:36:35 sparseml.modifiers.quantization.gptq.pytorch INFO     \n",
      "===== Compressing layer 20/22  =====\n",
      "2024-06-12 02:36:35 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.19.model.layers.19.self_attn.q_proj...\n",
      "2024-06-12 02:36:35 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:35 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 78.96\n",
      "2024-06-12 02:36:35 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.19.model.layers.19.self_attn.k_proj...\n",
      "2024-06-12 02:36:36 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:36 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 33.19\n",
      "2024-06-12 02:36:36 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.19.model.layers.19.self_attn.v_proj...\n",
      "2024-06-12 02:36:36 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:36 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 7.59\n",
      "2024-06-12 02:36:36 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.19.model.layers.19.self_attn.o_proj...\n",
      "2024-06-12 02:36:37 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:37 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.87\n",
      "2024-06-12 02:36:37 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.19.model.layers.19.mlp.gate_proj...\n",
      "2024-06-12 02:36:37 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:37 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 94.52\n",
      "2024-06-12 02:36:37 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.19.model.layers.19.mlp.up_proj...\n",
      "2024-06-12 02:36:37 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:37 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 68.14\n",
      "2024-06-12 02:36:37 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.19.model.layers.19.mlp.down_proj...\n",
      "2024-06-12 02:36:39 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 1.26\n",
      "2024-06-12 02:36:39 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 4.91\n",
      "2024-06-12 02:36:39 sparseml.modifiers.quantization.gptq.pytorch INFO     \n",
      "===== Compressing layer 21/22  =====\n",
      "2024-06-12 02:36:39 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.20.model.layers.20.self_attn.q_proj...\n",
      "2024-06-12 02:36:39 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:39 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 75.20\n",
      "2024-06-12 02:36:39 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.20.model.layers.20.self_attn.k_proj...\n",
      "2024-06-12 02:36:40 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:40 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 31.88\n",
      "2024-06-12 02:36:40 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.20.model.layers.20.self_attn.v_proj...\n",
      "2024-06-12 02:36:40 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:40 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 4.22\n",
      "2024-06-12 02:36:40 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.20.model.layers.20.self_attn.o_proj...\n",
      "2024-06-12 02:36:41 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:41 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 0.86\n",
      "2024-06-12 02:36:41 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.20.model.layers.20.mlp.gate_proj...\n",
      "2024-06-12 02:36:41 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:41 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 108.96\n",
      "2024-06-12 02:36:41 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.20.model.layers.20.mlp.up_proj...\n",
      "2024-06-12 02:36:41 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:41 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 79.45\n",
      "2024-06-12 02:36:41 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.20.model.layers.20.mlp.down_proj...\n",
      "2024-06-12 02:36:43 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 1.27\n",
      "2024-06-12 02:36:43 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 7.71\n",
      "2024-06-12 02:36:43 sparseml.modifiers.quantization.gptq.pytorch INFO     \n",
      "===== Compressing layer 22/22  =====\n",
      "2024-06-12 02:36:43 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.21.model.layers.21.self_attn.q_proj...\n",
      "2024-06-12 02:36:43 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.48\n",
      "2024-06-12 02:36:43 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 85.74\n",
      "2024-06-12 02:36:43 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.21.model.layers.21.self_attn.k_proj...\n",
      "2024-06-12 02:36:44 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:44 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 29.71\n",
      "2024-06-12 02:36:44 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.21.model.layers.21.self_attn.v_proj...\n",
      "2024-06-12 02:36:44 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:44 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 5.90\n",
      "2024-06-12 02:36:44 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.21.model.layers.21.self_attn.o_proj...\n",
      "2024-06-12 02:36:45 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.45\n",
      "2024-06-12 02:36:45 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 1.88\n",
      "2024-06-12 02:36:45 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.21.model.layers.21.mlp.gate_proj...\n",
      "2024-06-12 02:36:45 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.46\n",
      "2024-06-12 02:36:45 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 181.05\n",
      "2024-06-12 02:36:45 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.21.model.layers.21.mlp.up_proj...\n",
      "2024-06-12 02:36:45 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 0.46\n",
      "2024-06-12 02:36:45 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 108.65\n",
      "2024-06-12 02:36:45 sparseml.modifiers.utils.layer_compressor INFO     Compressing model.layers.21.model.layers.21.mlp.down_proj...\n",
      "2024-06-12 02:36:47 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     time 1.28\n",
      "2024-06-12 02:36:47 sparseml.modifiers.quantization.gptq.utils.gptq_wrapper INFO     error 17.28\n",
      "manager stage: Modifiers initialized\n",
      "manager stage: Modifiers finalized\n",
      "2024-06-12 02:36:47 sparseml.transformers.finetune.session_mixin INFO     Sparsification info for LlamaForCausalLM: 1100048384 total params. \n",
      "Calculating model sparsity: 100%|██████████| 155/155 [00:00<00:00, 3977.66it/s]\n",
      "2024-06-12 02:36:47 sparseml.transformers.finetune.session_mixin INFO     There are 1034420224 prunable params which have 1.4528439846125822 avg sparsity.\n",
      "2024-06-12 02:36:47 sparseml.transformers.finetune.session_mixin INFO     There are 1034420224 quantizable params, with a quantization percentage of 0.0.\n",
      "2024-06-12 02:36:47 sparseml.transformers.sparsification.compressed_tensors_utils INFO     Inferring a sparsity configuration requires a global sparsity calculation. This can be costly for large models. To skip the calculation of compression statistics set skip_compression_stats=True\n",
      "Calculating model sparsity: 100%|██████████| 201/201 [00:00<00:00, 7752.09it/s]\n",
      "Checking whether model follows 2:4 sparsity structure: 100%|██████████| 155/155 [00:00<00:00, 3370.88it/s]\n",
      "Calculating quantization compression ratio: 245it [00:00, 520.49it/s]\n",
      "2024-06-12 02:36:50 sparseml.pytorch.model_load.helpers INFO     Saving output to /home/rshaw/sparseml/examples/output\n"
     ]
    }
   ],
   "source": [
    "from sparseml.transformers import oneshot\n",
    "\n",
    "oneshot(\n",
    "    model=model,\n",
    "    dataset=ds,\n",
    "    recipe=recipe,\n",
    "    max_seq_length=2048,\n",
    "    num_calibration_samples=NUM_CALIBRATION_SAMPLES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Hello my name is John and my email is john@example.com I am interested in Hello my name is John and my email is john@example.com I am interested in Hello my name is John and my email is john@example.com I am interested in Hello my name is John and my email is john@example.com I am interested in Hello my name is John and my email is john@example.com I am interested in Hello my name is John and my email is\n"
     ]
    }
   ],
   "source": [
    "# Confirm generations of the quantized model look sane\n",
    "input_ids = tokenizer(\"Hello my name is\", return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "output = model.generate(input_ids, max_new_tokens=100)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Serialize the model\n",
    "\n",
    "Save the model using `save_pretrained` using `save_compressed=True`. This will save the weights in a compressed format, compatible for loading with vLLM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"llama-3-gptq-4-bit\"\n",
    "model.save_pretrained(OUTPUT_DIR, save_compressed=True)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparseml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
